{
    "body": "### Steps to reproduce\r\n\r\nThis is an issue with our E4S/21.11 deployment on Perlmutter regarding Lmod hierarcy. You can see the docs at: https://docs.nersc.gov/applications/e4s/perlmutter/21.11/ \r\n\r\nUsing Spack to generate lmod modules, we noticed that spack used the cray-mpich@8.1.12%gcc hash when building hypre with nvhpc compiler. Shown below is the dependency tree for hypre\r\n\r\n```\r\n==> 1 installed package\r\n-- cray-sles15-zen2 / nvhpc@21.9 --------------------------------\r\n5gcmt4fal5u3yvh6ylvchut6awpydhku hypre@2.23.0~complex+cuda~debug+fortran~int64~internal-superlu~mixedint+mpi+openmp+shared+superlu-dist~unified-memory cuda_arch=80\r\nlhlaiug5pk6vgaiovduzbtfhpuqyoml2     cray-libsci@21.08.1.2~mpi~openmp+shared\r\nmvyqt7umavgt4zarjcf2al3jgeyfg3bn     cray-mpich@8.1.12\r\n74g5tpcmu5yub2xxz5fsi43jk3ipwumz     cuda@11.4.0~dev\r\nurwlkw6ugcvzdqzskqinrotbf67e7zyj     superlu-dist@7.1.1~cuda~int64~ipo+openmp+shared build_type=RelWithDebInfo cuda_arch=none\r\nfbqiy4vpwmtelyrnzxyr52jh3ttoju5r         metis@5.1.0~gdb~int64~real64+shared build_type=Release patches=4991da938c1d3a1d3dea78e49bbebecba00273f98df2a656e38b83d55b281da1,b1225da886605ea558db7ac08dd8054742ea5afe5ed61ad4d0fe7a495b1270d2\r\nutafgctfr5twyzvkcropxqebuzjbphwr         parmetis@4.0.3~gdb~int64~ipo+shared build_type=RelWithDebInfo patches=4f892531eb0a807eb1b82e683a416d3e35154a455274cf9b162fb02054d11a5b,50ed2081bc939269689789942067c58b3e522c269269a430d5d34c00edbc5870,704b84f7c7444d4372cb59cca6e1209df4ef3b033bc4ee3cf50f369bce972a9d\r\n```\r\n\r\nThe cray-mpich packages are installed as external and we have the following packages explicitly installed in order to get the MPI hierarchy. Take a close look above the hash **mvyqt7umavgt4zarjcf2al3jgeyfg3bn** is a cray-mpich external for gcc and not nvhpc\r\n```\r\n==> 2 installed packages\r\n-- cray-sles15-zen2 / gcc@9.3.0 ---------------------------------\r\nmvyqt7umavgt4zarjcf2al3jgeyfg3bn cray-mpich@8.1.12\r\n \r\n-- cray-sles15-zen3 / nvhpc@21.9 --------------------------------\r\ne7ifg65itjdd55ryhdl3ifbxwny2rnpl cray-mpich@8.1.12\r\n```\r\n\r\n \r\nThis led to an interesting issue with Lmod hierarchy because hypre is in the wrong hierarchy tree due to its package preference. We see that **hypre%nvhpc** spec is using cray-mpich hash **mvyqt7u** \r\n\r\n```\r\n(spack-pyenv) siddiq90@login01> spack module lmod find --full-path hypre@2.23.0%nvhpc\r\n/global/u1/s/siddiq90/software.nersc.gov/spack-infrastructure/tmp/spack/opt/modules/lmod/cray-sles15-x86_64/cray-mpich/8.1.12-mvyqt7u/nvhpc/21.9/hypre/2.23.0-cuda.lua\r\n```\r\n\r\nThis means that this hypre module is now available in the gcc hierarchy when it should be in the  nvhpc tree. The package was built with nvhpc compiler but since its dependency cray-mpich is using gcc, spack will generate the module in the gcc hierarchy. \r\n\r\n```\r\nspack-pyenv) siddiq90@login01> ml gcc/9.3.0\r\n \r\nLmod is automatically replacing \"nvhpc/21.9\" with \"gcc/9.3.0\".\r\n \r\n \r\nDue to MODULEPATH changes, the following have been reloaded:\r\n  1) cray-mpich/8.1.12\r\n \r\n(spack-pyenv) siddiq90@login01> ml av\r\n \r\n /global/u1/s/siddiq90/software.nersc.gov/spack-infrastructure/tmp/spack/opt/modules/lmod/cray-sles15-x86_64/cray-mpich/8.1.12-mvyqt7u/gcc/9.3.0 \r\n   adios2/2.7.1      (D)    hypre/2.23.0               (D)    petsc/3.16.1      (D)    strumpack/6.1.0    (D)    upcxx/2021.9.0  (D)\r\n   amrex/21.11       (D)    kokkos-kernels/3.4.01-cuda        plumed/2.6.3      (D)    sundials/5.8.0     (D)    wannier90/3.1.0 (D)\r\n   hdf5/1.12.1       (D)    kokkos/3.4.01-cuda                slepc/3.16.0-cuda        superlu-dist/7.1.1 (D)\r\n   hypre/2.23.0-cuda        petsc/3.16.1-cuda                 slepc/3.16.0      (D)    trilinos/13.0.1    (D)\r\n \r\n----------- /global/u1/s/siddiq90/software.nersc.gov/spack-infrastructure/tmp/spack/opt/modules/lmod/cray-sles15-x86_64/gcc/9.3.0 -----------\r\n   cray-mpich/8.1.12 (L)    kokkos-kernels/3.4.01 (D)    papi/6.0.0.1        raja/0.14.0   (D)    umpire/6.0.0-cuda      zfp/0.5.5-cuda\r\n   gasnet/2021.9.0   (D)    kokkos/3.4.01         (D)    raja/0.14.0-cuda    superlu/5.3.0 (D)    upcxx/2021.9.0-cuda\r\n \r\n------------ /global/homes/s/siddiq90/software.nersc.gov/spack-infrastructure/tmp/spack/opt/modules/lmod/cray-sles15-x86_64/Core ------------\r\n   gcc/9.3.0 (L)    nvhpc/21.9\r\n```\r\n\r\nWe noticed that MODULEPATH for cray-mpich spec for nvhpc is using the wrong hash. It set to **e7ig65** for cray-mpich module from nvhpc \r\n\r\n```\r\nsiddiq90@login35> ml --redirect show cray-mpich | grep MODULEPATH\r\nprepend_path(\"MODULEPATH\",\"/global/common/software/spackecp/perlmutter/e4s-21.11/modules/lmod/cray-sles15-x86_64/cray-mpich/8.1.12-e7ifg65/nvhpc/21.9\")\r\n```\r\n\r\nIf you see the output of `ml av` the hypre spec is not present and we dont see a MODULEPATH for cray-mpich, thats because there are no modules written in this directory apparently because all of our specs used the external of `cray-mpich%gcc` as pose to `cray-mpich%nvhpc`.\r\n\r\n```\r\nsiddiq90@login35> ml av\r\n \r\n--------------------- /global/common/software/spackecp/perlmutter/e4s-21.11/modules/lmod/cray-sles15-x86_64/nvhpc/21.9 ----------------------\r\n   cray-mpich/8.1.12 (L)    umpire/6.0.0-cuda    upcxx/2021.9.0-cuda    zfp/0.5.5-cuda\r\n \r\n------------------------ /global/common/software/spackecp/perlmutter/e4s-21.11/modules/lmod/cray-sles15-x86_64/Core -------------------------\r\n   gcc/9.3.0    nvhpc/21.9 (L)\r\n```\r\n\r\nThe cray-mpich MODULEPATH for gcc external was correct. We need some guidance on how to setup Lmod MPI hierarchy for Cray system. \r\n\r\n```\r\nsiddiq90@login35> ml --redirect --raw show cray-mpich | grep MODULEPATH\r\nprepend_path(\"MODULEPATH\", \"/global/common/software/spackecp/perlmutter/e4s-21.11/modules/lmod/cray-sles15-x86_64/cray-mpich/8.1.12-mvyqt7u/gcc/9.3.0\")\r\n-- Change MODULEPATH based on the result of the tests above\r\n```\r\n\r\nOur spack configuration is available at https://github.com/spack/spack-configs/blob/main/NERSC/perlmutter/e4s-21.11/spack.yaml. \r\n\r\nWe set the following for our cray-mpich external\r\n\r\n```\r\n    cray-mpich:\r\n      buildable: false\r\n      externals:\r\n      - spec: cray-mpich@8.1.12 %gcc@9.3.0\r\n        prefix: /opt/cray/pe/mpich/8.1.12/ofi/gnu/9.1\r\n        modules:\r\n        - cray-mpich/8.1.12\r\n        - cudatoolkit/21.9_11.4\r\n      - spec: cray-mpich@8.1.12 %nvhpc@21.9\r\n        prefix: /opt/cray/pe/mpich/8.1.12/ofi/nvidia/20.7\r\n        modules:\r\n        - cray-mpich/8.1.12\r\n        - cudatoolkit/21.9_11.4\r\n```\r\n\r\n\r\nIn our specs we do matrix build and I suspect we would need to alter our matrix include ['`^cray-mpich%nvhpc'`]. I dont think we should have to do this but it looks like the package preference is the main cause of this issue since spack will prefer **gcc**, what i expect is if an entire DAG is built with a compiler it should honor all specs to be built with the same compiler and not mix-match. I think we need some more guidance building Lmod hierarchy and using multi compiler matrix build using a single MPI provider such as cray-mpich.\r\n\r\n```\r\n  packages:\r\n    all:\r\n      compiler: [gcc@9.3.0, nvhpc@21.9]\r\n```\r\n\r\n```\r\n  specs:\r\n  - matrix:\r\n    - [$gcc_specs]\r\n    - [$gcc_compilers]\r\n  - matrix:\r\n    - [$cuda_specs]\r\n    - [$gcc_compilers]\r\n  - matrix:\r\n    - [$nvhpc_specs]\r\n    - [$nvhpc_compilers]\r\n```\r\n\r\n### Error message\r\n\r\n_No response_\r\n\r\n### Information on your system\r\n\r\n```\r\nsiddiq90@login35> spack debug report\r\n* **Spack:** 0.17.0-2-80412b23ae\r\n* **Python:** 3.6.13\r\n* **Platform:** cray-sles15-zen3\r\n* **Concretizer:** clingo\r\n\r\n```\r\n\r\n### General information\r\n\r\n- [X] I have run `spack debug report` and reported the version of Spack/Python/Platform\r\n- [X] I have searched the issues of this repo and believe this is not a duplicate\r\n- [X] I have run the failing commands in debug mode and reported the output",
    "user": "shahzebsiddiqui",
    "url": "https://api.github.com/repos/spack/spack/issues/28667",
    "updated_at": "2022-01-28 16:53:39",
    "created_at": "2022-01-28 16:47:19",
    "closed_at": "None",
    "state": "open",
    "title": "Issue with Lmod Hierarchy with MPI using cray-mpich at Perlmutter",
    "number": 28667,
    "milestone": null,
    "labels": [
        "bug",
        "modules",
        "triage",
        "nersc"
    ],
    "id": 1117622209,
    "html_url": "https://github.com/spack/spack/issues/28667",
    "assignees": [],
    "comments": 0
}