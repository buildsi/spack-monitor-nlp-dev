{
    "body": "### Steps to reproduce\n\nI'm having all sorts of trouble trying to make a particular module available to Spack.  The module in question is `intel-mpi/2019.9.304`, and this expects a compiler module such as `gcc/9.3.0` to be preloaded.\r\n\r\nThe first problem I ran into is that there appears to be some magic I don't understand in the naming conventions used in Spack YAML files.  If I make up some arbitrary Spack package name, say, `happy-mpi`, I can't load the package at all:\r\n```console\r\n$ cat external.yaml \r\npackages:\r\n  happy-mpi:\r\n    buildable: false\r\n    externals:\r\n    - spec: happy-mpi@2019.9.304\r\n      modules:\r\n      - gcc/9.3.0\r\n      - intel-mpi/2019.9.304\r\n$ spack config add --file=external.yaml\r\n$ spack install happy-mpi\r\n==> Error: Package 'happy-mpi' not found.\r\n```\r\nChanging the name to `intel-mpi` gets me past the \"not found\" error (**why?**), but Spack doesn't like something about the underlying environment module:\r\n```console\r\n$ cat external.yaml \r\npackages:\r\n  intel-mpi:\r\n    buildable: false\r\n    externals:\r\n    - spec: intel-mpi@2019.9.304\r\n      modules:\r\n      - gcc/9.3.0\r\n      - intel-mpi/2019.9.304\r\n$ spack config add --file=external.yaml\r\n$ spack install intel-mpi\r\n==> intel-mpi@2019.9.304 : has external module in ['gcc/9.3.0', 'intel-mpi/2019.9.304']\r\n==> Warning: cannot perform the requested write operation on module files [Trying to source non-existing file: /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries/linux/mpi/intel64/bin/mpivars.sh]\r\n[+] /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64 (external intel-mpi-2019.9.304-5pqyb5c4ki6pdtfvzeebnn43tckwlhu2)\r\n```\r\nSure enough, I can't get to `mpicc` and friends.  Here's where everything is supposed to be if I ignore Spack and load the modules myself:\r\n```console\r\n$ module load gcc/9.3.0\r\n$ module load intel-mpi/2019.9.304\r\n$ which mpivars.sh\r\n/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/bin/mpivars.sh\r\n$ which mpicc\r\n/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/bin/mpicc\r\n```\n\n### Error message\n\n```console\r\n$ spack --debug --stacktrace install intel-mpi\r\n.mdt3/pakin/spack/lib/spack/spack/cmd/__init__.py:123 ==> [2021-12-21-18:40:14.362461] Imported install from built-in commands\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.369194] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/config.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/cmd/__init__.py:123 ==> [2021-12-21-18:40:14.401118] Imported install from built-in commands\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.407160] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/bootstrap.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.425904] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/config.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/database.py:374 ==> [2021-12-21-18:40:14.456383] DATABASE LOCK TIMEOUT: 3s\r\n.mdt3/pakin/spack/lib/spack/spack/database.py:378 ==> [2021-12-21-18:40:14.456869] PACKAGE LOCK TIMEOUT: No timeout\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.457919] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/bootstrap.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/database.py:374 ==> [2021-12-21-18:40:14.471739] DATABASE LOCK TIMEOUT: 3s\r\n.mdt3/pakin/spack/lib/spack/spack/database.py:378 ==> [2021-12-21-18:40:14.472310] PACKAGE LOCK TIMEOUT: No timeout\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:605 ==> [2021-12-21-18:40:14.472773] [BOOTSTRAP CONFIG SCOPE] name=_builtin\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:621 ==> [2021-12-21-18:40:14.473638] [BOOTSTRAP CONFIG SCOPE] name=defaults, path=/lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:622 ==> [2021-12-21-18:40:14.474054] [BOOTSTRAP CONFIG SCOPE] name=defaults/linux, path=/lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/linux\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:621 ==> [2021-12-21-18:40:14.474460] [BOOTSTRAP CONFIG SCOPE] name=bootstrap, path=/users/pakin/.spack/bootstrap/config\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:622 ==> [2021-12-21-18:40:14.474856] [BOOTSTRAP CONFIG SCOPE] name=bootstrap/linux, path=/users/pakin/.spack/bootstrap/config/linux\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.477065] Reading config file /users/pakin/.spack/bootstrap/config/linux/compilers.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:754 ==> [2021-12-21-18:40:14.525211] [BOOTSTRAP ROOT SPEC] clingo-bootstrap@spack+python %gcc target=x86_64\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:506 ==> [2021-12-21-18:40:14.525570] [BOOTSTRAP MODULE clingo] Try importing from Python\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.526392] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/bootstrap.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.885854] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/config.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/bootstrap.py:100 ==> [2021-12-21-18:40:14.983077] [BOOTSTRAP MODULE clingo] The installed spec \"clingo-bootstrap@spack+python %gcc target=x86_64 ^python@3.6 /vcipwnf57slgoo7busvvkzjkk7vydeb5\" provides the \"clingo\" Python module\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:14.983865] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/repos.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:17.299871] Reading config file /users/pakin/.spack/linux/compilers.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:17.311326] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/config.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:17.342279] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/packages.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:17.389837] Reading config file /users/pakin/.spack/packages.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/solver/asp.py:1961 ==> [2021-12-21-18:40:23.613893] build(intel-mpi)\r\n.mdt3/pakin/spack/lib/spack/spack/util/module_cmd.py:171 ==> [2021-12-21-18:40:24.154033] Module name: gcc/9.3.0\r\n.mdt3/pakin/spack/lib/spack/spack/util/module_cmd.py:178 ==> [2021-12-21-18:40:24.154617] Package directory variable prefix: GCC\r\n.mdt3/pakin/spack/lib/spack/spack/util/module_cmd.py:171 ==> [2021-12-21-18:40:24.790603] Module name: intel-mpi/2019.9.304\r\n.mdt3/pakin/spack/lib/spack/spack/util/module_cmd.py:178 ==> [2021-12-21-18:40:24.791452] Package directory variable prefix: INTEL_MPI\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:1437 ==> [2021-12-21-18:40:24.811138] Initializing the build queue from the build requests\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:1053 ==> [2021-12-21-18:40:24.811495] Initializing the build queue for intel-mpi\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:325 ==> [2021-12-21-18:40:24.812166] intel-mpi@2019.9.304 : is actually installed in /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:333 ==> [2021-12-21-18:40:24.812467] intel-mpi@2019.9.304 : already registered in DB\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:343 ==> [2021-12-21-18:40:24.818059] intel-mpi@2019.9.304 : generating module file\r\n.mdt3/pakin/spack/lib/spack/spack/hooks/sbang.py:242 ==> [2021-12-21-18:40:24.827271] SKIP: shebang filtering [external package]\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:24.828615] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/modules.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/config.py:1006 ==> [2021-12-21-18:40:24.846152] Reading config file /lustre/scratch4/yellow/.mdt3/pakin/spack/etc/spack/defaults/linux/modules.yaml\r\n.mdt3/pakin/spack/lib/spack/spack/modules/common.py:859 ==> [2021-12-21-18:40:24.859690] \tWRITE: intel-mpi@2019.9.304%gcc@4.8.5~external-libfabric arch=linux-rhel7-haswell/5pqyb5c [/lustre/scratch4/yellow/.mdt3/pakin/spack/share/spack/modules/linux-rhel7-haswell/intel-mpi-2019.9.304-gcc-4.8.5-5pqyb5c]\r\n.mdt3/pakin/spack/lib/spack/spack/build_systems/intel.py:47 ==> [2021-12-21-18:40:25.152463] normalize_path.normalize_suite_dir:\ttrying /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries_2019.9.304\r\n.mdt3/pakin/spack/lib/spack/spack/build_systems/intel.py:47 ==> [2021-12-21-18:40:25.157164] normalize_path.normalize_suite_dir:\ttrying /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries_2019.9.*\r\n.mdt3/pakin/spack/lib/spack/spack/build_systems/intel.py:47 ==> [2021-12-21-18:40:25.161122] normalize_path.normalize_suite_dir:\ttrying /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries_*.*.*\r\n.mdt3/pakin/spack/lib/spack/spack/build_systems/intel.py:47 ==> [2021-12-21-18:40:25.165006] normalize_path.normalize_suite_dir:\t/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries\r\n.mdt3/pakin/spack/lib/spack/spack/build_systems/intel.py:47 ==> [2021-12-21-18:40:25.168421] file_to_source.normalize_path:\t/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries/linux/mpi/intel64/bin/mpivars.sh\r\n.mdt3/pakin/spack/lib/spack/spack/build_systems/intel.py:1032 ==> [2021-12-21-18:40:25.168935] sourcing /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries/linux/mpi/intel64/bin/mpivars.sh\r\n.mdt3/pakin/spack/lib/spack/spack/util/environment.py:666 ==> [2021-12-21-18:40:25.169470] EnvironmentModifications.from_sourcing_file: /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries/linux/mpi/intel64/bin/mpivars.sh\r\n.mdt3/pakin/spack/lib/spack/spack/hooks/module_file_generation.py:36 ==> [2021-12-21-18:40:25.169931] Warning: cannot perform the requested write operation on module files [Trying to source non-existing file: /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/compilers_and_libraries/linux/mpi/intel64/bin/mpivars.sh]\r\n.mdt3/pakin/spack/lib/spack/spack/hooks/module_file_generation.py:26 ==> [2021-12-21-18:40:25.170381] NO MODULE WRITTEN: list of enabled module files is empty\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:347 ==> [2021-12-21-18:40:25.170703] intel-mpi@2019.9.304 : registering into DB\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:1415 ==> [2021-12-21-18:40:25.230204] Flagging intel-mpi-2019.9.304-5pqyb5c4ki6pdtfvzeebnn43tckwlhu2 as installed\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:1443 ==> [2021-12-21-18:40:25.230523] Ensure all dependencies know all dependents across specs\r\n.mdt3/pakin/spack/lib/spack/spack/installer.py:323 ==> [2021-12-21-18:40:24.811857] intel-mpi@2019.9.304 : has external module in ['gcc/9.3.0', 'intel-mpi/2019.9.304']\r\n[+] /usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64 (external intel-mpi-2019.9.304-5pqyb5c4ki6pdtfvzeebnn43tckwlhu2)\r\n```\n\n### Information on your system\n\nI'm using Snow, a LANL CTS-1 machine running TOSS3.\r\n\r\n```console\r\n$ spack debug report\r\n* **Spack:** 0.17.0-625-522a7c8ee0\r\n* **Python:** 3.6.8\r\n* **Platform:** linux-rhel7-broadwell\r\n* **Concretizer:** clingo\r\n$ module show intel-mpi/2019.9.304\r\n----------------------------------------------------------------------------------------------------------------------------------------------------------\r\n   /usr/projects/hpcsoft/modulefiles/toss3/snow/mpi/intel-mpi/2019.9.304:\r\n----------------------------------------------------------------------------------------------------------------------------------------------------------\r\nconflict(\"intel-mpi\",\"openmpi\",\"mvapich2\")\r\nwhatis(\"Intel MPI 2019.9.304 \")\r\nsetenv(\"LMPI\",\"intel-mpi\")\r\nsetenv(\"LMPIVER\",\"2019.9.304\")\r\nsetenv(\"MPIHOME\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304\")\r\nsetenv(\"MPI_NAME\",\"intel-mpi\")\r\nsetenv(\"MPI_VERSION\",\"2019.9.304\")\r\nsetenv(\"MPI_ROOT\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304\")\r\nsetenv(\"I_MPI_ROOT\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304\")\r\nsetenv(\"SLURM_MPI_TYPE\",\"pmi2\")\r\nsetenv(\"I_MPI_HYDRA_PMI_CONNECT\",\"alltoall\")\r\nprepend_path(\"PATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/bin\")\r\nprepend_path(\"CPATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/include\")\r\nprepend_path(\"LD_LIBRARY_PATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/lib/release\")\r\nprepend_path(\"LD_LIBRARY_PATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/lib\")\r\nprepend_path(\"LD_LIBRARY_PATH\",\"\")\r\nprepend_path(\"PATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/bin\")\r\nprepend_path(\"CPATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/include\")\r\nprepend_path(\"LD_LIBRARY_PATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/intel64/lib\")\r\nprepend_path(\"MANPATH\",\"/usr/projects/hpcsoft/toss3/common/x86_64/intel-clusterstudio/2020.4.912/impi/2019.9.304/man\")\r\nhelp([[ Intel MPI 2019.9.304\r\n\r\n        For best performance, launch jobs with SLURM's srun command:\r\n           $ srun -n <num_procs> a.out\r\n\r\n        This supports process tracking, accounting, task affinity,\r\n        suspend/resume and other features.\r\n\r\n        Supported Compilers\r\n        ===================\r\n        The MPI compilers (mpicc, mpicxx, mpif90, etc) only work\r\n        with the GNU and Intel compilers. If using either PGI\r\n        or Pathscale compilers you will have to use their native\r\n        compilers and explicitly include the MPI header files and\r\n        link in MPI library files. For example:\r\n            $pgf90 -o my.exe -I${MPIHOME}/intel64/include my.f90 \\\r\n                    -L${MPIHOME}/intel64/lib -lmpi ...\r\n\r\n        ${MPIHOME} is set by this module file.\r\n\r\n]])\r\n```\n\n### General information\n\n- [X] I have run `spack debug report` and reported the version of Spack/Python/Platform\n- [X] I have searched the issues of this repo and believe this is not a duplicate\n- [X] I have run the failing commands in debug mode and reported the output",
    "user": "spakin",
    "url": "https://api.github.com/repos/spack/spack/issues/28123",
    "updated_at": "2021-12-24 14:01:36",
    "created_at": "2021-12-22 01:50:54",
    "closed_at": "None",
    "state": "open",
    "title": "Trouble providing external package from module",
    "number": 28123,
    "milestone": null,
    "labels": [
        "bug",
        "compilers",
        "modules",
        "triage"
    ],
    "id": 1086371225,
    "html_url": "https://github.com/spack/spack/issues/28123",
    "assignees": [],
    "comments": 0
}