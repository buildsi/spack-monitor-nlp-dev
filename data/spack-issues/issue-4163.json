{
    "body": "**NEEDS FACT CHECKING**.  For convenience, the relevant section of the `SuiteSparse_config.mk` file is\r\n\r\n```\r\n    #---------------------------------------------------------------------------\r\n    # NVIDIA CUDA configuration for CHOLMOD and SPQR\r\n    #---------------------------------------------------------------------------\r\n\r\n    # CUDA is detected automatically, and used if found.  To disable CUDA,\r\n    # use CUDA=no\r\n\r\n    ifneq ($(CUDA),no)\r\n        CUDA_PATH = $(shell which nvcc 2>/dev/null | sed \"s/\\/bin\\/nvcc//\")\r\n    endif\r\n\r\n    ifeq ($(wildcard $(CUDA_PATH)),)\r\n        # CUDA is not present\r\n        CUDA_PATH     =\r\n        GPU_BLAS_PATH =\r\n        GPU_CONFIG    =\r\n        CUDART_LIB    =\r\n        CUBLAS_LIB    =\r\n        CUDA_INC_PATH =\r\n        CUDA_INC      =\r\n        NVCC          = echo\r\n        NVCCFLAGS     =\r\n    else\r\n        # with CUDA for CHOLMOD and SPQR\r\n        GPU_BLAS_PATH = $(CUDA_PATH)\r\n        # GPU_CONFIG must include -DGPU_BLAS to compile SuiteSparse for the\r\n        # GPU.  You can add additional GPU-related flags to it as well.\r\n        # with 4 cores (default):\r\n        GPU_CONFIG    = -DGPU_BLAS\r\n        # For example, to compile CHOLMOD for 10 CPU cores when using the GPU:\r\n        # GPU_CONFIG  = -DGPU_BLAS -DCHOLMOD_OMP_NUM_THREADS=10\r\n        CUDART_LIB    = $(CUDA_PATH)/lib64/libcudart.so\r\n        CUBLAS_LIB    = $(CUDA_PATH)/lib64/libcublas.so\r\n        CUDA_INC_PATH = $(CUDA_PATH)/include/\r\n        CUDA_INC      = -I$(CUDA_INC_PATH)\r\n        NVCC          = $(CUDA_PATH)/bin/nvcc\r\n        NVCCFLAGS     = -Xcompiler -fPIC -O3 \\\r\n                            -gencode=arch=compute_30,code=sm_30 \\\r\n                            -gencode=arch=compute_35,code=sm_35 \\\r\n                            -gencode=arch=compute_50,code=sm_50 \\\r\n                            -gencode=arch=compute_50,code=compute_50\r\n    endif\r\n```\r\n\r\nBasically, I'm sure the original author put this part I deleted in there since `cuda` hasn't been in `spack` for very long.  Since `cuda` is available now, though, this seems to be the correct way to do it -- hack around them doing `which nvcc` and then set `CUDA_PATH` based off what `spack` does.\r\n\r\n1. I can only confirm that the libraries (e.g. `libSuiteSparse_GPURuntime.so`) are able to be built (when `+cuda`).\r\n    - `ls -al | wc -l` was my fact checker, `42` for `~cuda` and `48` for `+cuda`.\r\n2. I tried like heck to get their coverage tests `make cov` to work, but similar to the `patch` being applied to the file, I would have had to go through and find all of the places where instead of `LAPACK ?= thing` they do `LAPACK = thing`...and I don't feel like doing that.\r\n3. I have no idea how to write any code using this library or its CUDA capabilities, and a brief scan of the internet makes me think it would be a lot better if somebody who actually knows what to do tested this rather than somebody (me) who has no idea whether the code they're writing is correct and the library build failed, or vice versa.\r\n\r\nBasically, the fact that the libraries build lead me to believe it is working as expected, but this should definitely have some testing done by others before blindly merging -- `suite-sparse` is a core package and this is going to change the hashes (added a variant)...",
    "user": "svenevs",
    "url": "https://api.github.com/repos/spack/spack/issues/4163",
    "updated_at": "2017-05-11 22:35:43",
    "created_at": "2017-05-09 00:55:48",
    "closed_at": "2017-05-10 13:13:15",
    "state": "closed",
    "title": "enable cuda support for suite-sparse",
    "number": 4163,
    "milestone": null,
    "labels": [],
    "id": 227216918,
    "html_url": "https://github.com/spack/spack/pull/4163",
    "assignees": [],
    "comments": 7
}