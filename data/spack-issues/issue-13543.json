{
    "body": "I installed mpich 3.3 (hash `diz4f6i`) back in April and have been using it since without any problems to install other packages that depend on MPI.  After switching to version v0.13.0, when I try to reuse the mpich install the concretization wants to reinstall mpich3.3.  Please excuse my abuse of spack terminology.\r\n\r\nThe following commands and output were on our production RHEL7 system:\r\n\r\n```\r\n$ spack spec -I p4est%gcc@7.3.0 ^ /diz4f6i\r\nInput spec\r\n--------------------------------\r\n -   p4est%gcc@7.3.0\r\n -       ^mpich@3.3%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  device=ch3 +hydra netmod=tcp patches=c7d4ecf865dccff5b764d9c66b6a470d11b0b1a5b4f7ad1ffa61079ad6b5dede +pci pmi=pmi +romio~slurm~verbs arch=linux-rhel7-x86_64\r\n[+]          ^libpciaccess@0.13.5%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]          ^libxml2@2.9.8%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\" ~python arch=linux-rhel7-x86_64\r\n[+]              ^libiconv@1.15%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]              ^xz@system%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]              ^zlib@1.2.11%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\" +optimize+pic+shared arch=linux-rhel7-x86_64\r\n\r\nConcretized\r\n--------------------------------\r\n -   p4est@2.2%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\" +mpi~openmp arch=linux-rhel7-x86_64\r\n[+]      ^autoconf@system%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]      ^automake@system%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]      ^libtool@2.4.6%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]          ^m4@1.4.16%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\" +sigsegv arch=linux-rhel7-x86_64\r\n -       ^mpich@3.3%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  device=ch3 +hydra netmod=tcp patches=c7d4ecf865dccff5b764d9c66b6a470d11b0b1a5b4f7ad1ffa61079ad6b5dede +pci pmi=pmi +romio~slurm~verbs arch=linux-rhel7-x86_64\r\n[+]          ^libpciaccess@0.13.5%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]          ^libxml2@2.9.8%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\" ~python arch=linux-rhel7-x86_64\r\n[+]              ^libiconv@1.15%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]              ^xz@system%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\"  arch=linux-rhel7-x86_64\r\n[+]              ^zlib@1.2.11%gcc@7.3.0 cflags=\"-mtune=native -march=core2\" cxxflags=\"-mtune=native -march=core2\" fflags=\"-mtune=native -march=core2\" +optimize+pic+shared arch=linux-rhel7-x86_64\r\n```\r\n\r\n### Steps to reproduce the issue\r\n\r\nTo sanity check what I was seeing I moved to my arch linux workstation and a fresh/empty spack instance.\r\n\r\nThe following steps will install mpich 3.3 using a spack commit from around April, then switch to the v0.13.0 release and attempt to use the mpich 3.3 install to install p4est.\r\n\r\n```\r\ncd /path/to/spack/source\r\nexport SPACK_ROOT=$PWD\r\nexport PATH=$SPACK_ROOT/bin:$PATH\r\nsource $SPACK_ROOT/share/spack/setup-env.sh\r\ngit checkout 263d8a818\r\nspack install mpich@3.3\r\nspack find -ldv mpich@3.3 # get the hash\r\ngit checkout v0.13.0\r\nspack spec -I p4est ^/<mpich3.3 hash>\r\n```\r\n\r\n### Error Message\r\n\r\nOn my arch linux workstation `awcodyi` is the hash for the just installed mpich3.3.  The output below lists the concretized `p4est` spec not using the existing mpich 3.3 install.  Is this expected?\r\n\r\n```\r\n$ spack find -ldv mpich@3.3\r\n==> 1 installed package\r\n-- linux-archrolling-x86_64 / gcc@9.1.0 -------------------------\r\nawcodyi mpich@3.3 device=ch3 +hydra netmod=tcp patches=c7d4ecf865dccff5b764d9c66b6a470d11b0b1a5b4f7ad1ffa61079ad6b5dede +pci pmi=pmi +romio~slurm~verbs\r\nlmz4l2x     libpciaccess@0.13.5\r\nabz5o7u     libxml2@2.9.8~python\r\nbydq6w2         libiconv@1.15\r\n6gclrwk         xz@system\r\n73f2u3d         zlib@1.2.11+optimize+pic+shared\r\n```\r\n\r\n```\r\n$ spack spec -I p4est%gcc@9.1.0 ^/awcodyi\r\nInput spec\r\n--------------------------------\r\n -   p4est%gcc@9.1.0\r\n -       ^mpich@3.3%gcc@9.1.0 device=ch3 +hydra netmod=tcp patches=c7d4ecf865dccff5b764d9c66b6a470d11b0b1a5b4f7ad1ffa61079ad6b5dede +pci pmi=pmi +romio~slurm~verbs arch=linux-archrolling-x86_64\r\n[+]          ^libpciaccess@0.13.5%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -           ^libxml2@2.9.8%gcc@9.1.0~python arch=linux-archrolling-x86_64\r\n[+]              ^libiconv@1.15%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -               ^xz@system%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n[+]              ^zlib@1.2.11%gcc@9.1.0+optimize+pic+shared arch=linux-archrolling-x86_64\r\n\r\nConcretized\r\n--------------------------------\r\n -   p4est@2.2%gcc@9.1.0+mpi~openmp arch=linux-archrolling-x86_64\r\n -       ^autoconf@system%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -       ^automake@system%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -       ^libtool@2.4.6%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -           ^m4@1.4.18%gcc@9.1.0 patches=3877ab548f88597ab2327a2230ee048d2d07ace1062efe81fc92e91b7f39cd00,fc9b61654a3ba1a8d6cd78ce087e7c96366c290bc8d2c299f09828d793b853c8 +sigsegv arch=linux-archrolling-x86_64\r\n -               ^libsigsegv@2.12%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -       ^mpich@3.3%gcc@9.1.0 device=ch3 +hydra netmod=tcp patches=c7d4ecf865dccff5b764d9c66b6a470d11b0b1a5b4f7ad1ffa61079ad6b5dede +pci pmi=pmi +romio~slurm~verbs+wrapperrpath arch=linux-archrolling-x86_64\r\n[+]          ^findutils@4.6.0%gcc@9.1.0 patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2 arch=linux-archrolling-x86_64\r\n -               ^texinfo@6.5%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -                   ^perl@system%gcc@9.1.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-archrolling-x86_64\r\n[+]          ^libpciaccess@0.13.5%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -           ^libxml2@2.9.8%gcc@9.1.0~python arch=linux-archrolling-x86_64\r\n[+]              ^libiconv@1.15%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -               ^pkgconf@1.6.3%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n -               ^xz@system%gcc@9.1.0 arch=linux-archrolling-x86_64\r\n[+]              ^zlib@1.2.11%gcc@9.1.0+optimize+pic+shared arch=linux-archrolling-x86_64\r\n```\r\n\r\n### Information on your system\r\n\r\nThis includes:\r\n\r\n 1. which platform you are using: arch linux\r\n 2. any relevant configuration detail (custom `packages.yaml` or `modules.yaml`, etc.): `packages.yaml` sets paths to system installs of autoconf, automake, etc.\r\n",
    "user": "cwsmith",
    "url": "https://api.github.com/repos/spack/spack/issues/13543",
    "updated_at": "2019-11-01 20:06:13",
    "created_at": "2019-11-01 19:57:43",
    "closed_at": "2019-11-01 20:06:06",
    "state": "closed",
    "title": "problem reusing old install after updating spack to v0.13.0",
    "number": 13543,
    "milestone": null,
    "labels": [
        "bug",
        "duplicate",
        "concretization",
        "help wanted"
    ],
    "id": 516316659,
    "html_url": "https://github.com/spack/spack/issues/13543",
    "assignees": [],
    "comments": 1
}